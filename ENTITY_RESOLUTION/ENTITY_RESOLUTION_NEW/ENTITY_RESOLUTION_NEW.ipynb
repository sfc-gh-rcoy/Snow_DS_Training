{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "acrb322i26ectjpdqtuk",
   "authorId": "4503098686890",
   "authorName": "AMELATTI",
   "authorEmail": "anthony.melatti@snowflake.com",
   "sessionId": "ee947203-06cf-4d13-b8e0-cf576d3c01f9",
   "lastEditTime": 1753913137720
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "source": "a = pd.read_csv('Amazon.csv',  encoding='unicode_escape')\na.columns = [c.upper() for c in a.columns]\namazon = session.create_dataframe(a)\namazon.write.mode(\"overwrite\").save_as_table(\"amazon_items\")\n\ng = pd.read_csv('GoogleProducts.csv',  encoding='unicode_escape')\ng.columns = [c.upper() for c in g.columns]\ngoogle = session.create_dataframe(g)\ngoogle.write.mode(\"overwrite\").save_as_table(\"google_items\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "510e28c9-db87-48d0-a7dd-f434b9b4f7a9",
   "metadata": {
    "name": "cell4",
    "collapsed": false
   },
   "source": "First create a lookup table representing the largest table. We want 2 columns, an ID column and a column with all the information related to the ID/Product"
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "sql",
    "name": "cell3"
   },
   "source": "UPDATE amazon_items\nSET \n    title = COALESCE(title, 'NA'),\n    DESCRIPTION = COALESCE(DESCRIPTION, 'NA'),\n    manufacturer = COALESCE(manufacturer, 'NA'),\n    Price = COALESCE(Price, 'NA')\nWHERE \n    title IS NULL OR DESCRIPTION IS NULL OR manufacturer IS NULL;\n\ncreate or replace table amazon_lookup as\nselect ID, 'Name: '||title||', Description: '||DESCRIPTION ||', Manufacturer: '||manufacturer||', Price: '||Price as ITEM\nfrom amazon_items;\n     ",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "fd8ac111-cb66-404b-bfce-477f19a72a21",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": "current_wh = session.get_current_warehouse()\ncurrent_db = session.get_current_database()\ncurrent_schema = session.get_current_schema()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ae5e5efe-c485-46b9-a484-b8e02c6a5be9",
   "metadata": {
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": "session.sql(f'''CREATE OR REPLACE CORTEX SEARCH SERVICE PRODUCT_LOOKUP\n  ON ITEM\n  ATTRIBUTES ID\n  WAREHOUSE = {current_wh}\n  TARGET_LAG = '1 day'\n  EMBEDDING_MODEL = 'snowflake-arctic-embed-l-v2.0'\n  AS (\n    SELECT\n        ID,\n        ITEM\n    FROM amazon_lookup)''')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "45a7ed3d-7ede-4dfe-9284-d57625e4d828",
   "metadata": {
    "language": "sql",
    "name": "cell7"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE PROCEDURE batch_cortex_search(\n    db_name STRING, \n    schema_name STRING, \n    service_name STRING, \n    queries ARRAY, \n    columns ARRAY, \n    n_jobs INTEGER DEFAULT -1\n)\nRETURNS VARIANT\nLANGUAGE PYTHON\nPACKAGES = ('snowflake-snowpark-python==1.9.0', 'joblib==1.4.2', 'backoff==2.2.1')\nRUNTIME_VERSION = '3.10'\nHANDLER = 'main'\nAS\n$$\nimport _snowflake\nimport json\nfrom joblib import Parallel, delayed\nimport backoff\nfrom snowflake.snowpark import Session\nfrom snowflake.snowpark.functions import col\n\n# Helper function to call the API with retry logic\n@backoff.on_exception(backoff.expo, Exception, max_tries=5, giveup=lambda e: not (isinstance(e, Exception) and hasattr(e, \"args\") and len(e.args) > 0 and isinstance(e.args[0], dict) and e.args[0].get(\"status\") == 429))\ndef call_api(db_name, schema_name, service_name, request_body):\n    \"\"\"Calls the Cortex Search REST API with retry logic for rate limiting.\"\"\"\n    resp = _snowflake.send_snow_api_request(\n        \"POST\",\n        f\"/api/v2/databases/{db_name}/schemas/{schema_name}/cortex-search-services/{service_name}:query\",\n        {},\n        {},\n        request_body,\n        {},\n        30000,\n    )\n    if resp[\"status\"] == 429:\n        raise Exception({\"status\": resp[\"status\"], \"content\": resp[\"content\"]})\n    return resp\n\n# Function to call the API for a single query\ndef search(db_name, schema_name, service_name, query, columns):\n    \"\"\"Calls the Cortex Search REST API and returns the response without filters.\"\"\"\n    \n    request_body = {\n        \"query\": query,\n        \"columns\": columns,\n        \"limit\": 1, # You can adjust this limit if needed\n    }\n    try:\n        resp = call_api(db_name, schema_name, service_name, request_body)\n        if resp[\"status\"] < 400:\n            response_content = json.loads(resp[\"content\"])\n            results = response_content.get(\"results\", [])\n            return {\"query\": query, \"results\": results}\n        else:\n            return {\"query\": query, \"results\": f\"Failed request with status {resp['status']}: {resp}\"}\n    except Exception as e:\n        return {\"query\": query, \"results\": f\"API Error: {e}\"}\n\n# Function to process queries concurrently using batch size\ndef concurrent_searches(db_name, schema_name, service_name, queries, columns, n_jobs):\n    \"\"\"Calls the Cortex Search REST API for multiple queries and returns the response without filters.\"\"\"\n    results = Parallel(n_jobs=n_jobs, backend='threading')(\n        delayed(search)(db_name, schema_name, service_name, q, columns) for q in queries\n    )\n    return results\n\n# Main function to handle batching and inserting results\ndef main(session: Session, db_name, schema_name, service_name, queries, columns, n_jobs):\n    if isinstance(queries, list) and len(queries) > 0:\n        # Split queries into batches of 500\n        batch_size = 500\n        total_queries = len(queries)\n        batches = [queries[i:i + batch_size] for i in range(0, total_queries, batch_size)]\n        \n        # Loop through each batch and process\n        for batch in batches:\n            # Perform concurrent searches for this batch\n            batch_results = concurrent_searches(db_name, schema_name, service_name, batch, columns, n_jobs)\n            \n            # Create a list to hold the results for batch insertion\n            insert_values = []\n\n            # Prepare the results for batch insert\n            for result in batch_results:\n                insert_values.append({\n                    \"QUERY\": result[\"query\"],\n                    \"RESULTS\": json.dumps(result[\"results\"])\n                })\n\n            # Insert the results into the BATCH_SEARCH_RESULTS table using Snowpark\n            if insert_values:\n                # Create a DataFrame with the results\n                df = session.create_dataframe(insert_values)\n\n                # Perform the batch insert into BATCH_SEARCH_RESULTS\n                df.write.mode(\"append\").save_as_table(\"BATCH_SEARCH_RESULTS\")\n\n        return {\"status\": \"Success\", \"message\": f\"{total_queries} queries processed in batches.\"}\n    else:\n        raise ValueError(\"Queries must be an array of query text\")\n$$;\n     ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6a5800f4-4094-4de8-8a41-cf5da2c48866",
   "metadata": {
    "language": "sql",
    "name": "cell8"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE TABLE BATCH_SEARCH_RESULTS (\n    QUERY STRING,\n    RESULTS STRING\n);\n     ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "229ab8c7-775c-40db-bddb-fb91a140dbec",
   "metadata": {
    "language": "sql",
    "name": "cell9"
   },
   "outputs": [],
   "source": "\nUPDATE google_items\nSET \n    name = COALESCE(name, 'NA'),\n    DESCRIPTION = COALESCE(DESCRIPTION, 'NA'),\n    manufacturer = COALESCE(manufacturer, 'NA'),\n    Price = COALESCE(Price, 'NA')\nWHERE \n    name IS NULL OR DESCRIPTION IS NULL OR manufacturer IS NULL;\n    \ncreate or replace table google_lookup as\nselect ID, 'Name: '||name||', Description: '||DESCRIPTION ||', Manufacturer: '||manufacturer||', Price: '||Price as ITEM\nfrom google_items;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3abe91fd-7195-4021-b255-a384def1e642",
   "metadata": {
    "language": "python",
    "name": "cell10"
   },
   "outputs": [],
   "source": "#  Replace lines 5 and 6 with your DB and Schema\n\nsession.sql(f'''\nCALL batch_cortex_search(\n    'LLMOPS_DB',\n    'LLMOPS_SCHEMA',\n    'PRODUCT_LOOKUP',\n    (SELECT ARRAY_AGG(ITEM) FROM google_lookup),\n    ARRAY_CONSTRUCT('ID','ITEM'),\n    -1\n)\n''')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1668ac99-0579-4a49-ab49-500204bcb23d",
   "metadata": {
    "language": "sql",
    "name": "cell11"
   },
   "outputs": [],
   "source": "select * from BATCH_SEARCH_RESULTS;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b56aa97a-e271-4ac6-ac39-95d6b2df8c17",
   "metadata": {
    "language": "sql",
    "name": "cell12"
   },
   "outputs": [],
   "source": "create or replace table google_amazon_items as\nselect \nquery, \nvalue:ITEM::varchar as matched_item_info, \nvalue:ID::varchar as amazon_id,\n-- value:\"@CONFIDENCE_SCORE\"::int as score\nvalue:\"@scores\":cosine_similarity::float as score\nfrom BATCH_SEARCH_RESULTS,\nlateral FLATTEN(INPUT => parse_json(results));\n\ncreate or replace table google_amazon_matches as\nselect Amazon_ID,\nid as google_id,\nquery as google_desc,\nmatched_item_info as amazon_desc,\nscore\nfrom google_amazon_items a\nleft join\ngoogle_lookup g\non a.query = g.item;\n\nselect * from google_amazon_matches limit 10;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c53a29dc-5ae0-4bcf-a0d2-e1f182a09535",
   "metadata": {
    "language": "sql",
    "name": "cell13"
   },
   "outputs": [],
   "source": "create or replace table snowflake_matches\nas\nselect amazon_id, \ngoogle_id\nfrom google_amazon_matches\nwhere score >= 0.8;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e9546207-b1c6-4ab7-9b45-33df4f31284b",
   "metadata": {
    "language": "sql",
    "name": "cell14"
   },
   "outputs": [],
   "source": "create or replace table matches_w_claude as\nSELECT amazon_id, google_id, amazon_desc, google_desc, score, SNOWFLAKE.CORTEX.COMPLETE(\n    'claude-3-7-sonnet',\n        CONCAT('You are responsible for identifying if two products are the same product even though there may be some slight differences since they are sold on two different websites.\nGiven the descriptions of the two products, return a 1 if they are likely the same product, 0 if they are not.\nItem 1 Description: ', AMAZON_DESC,\n' Item 2 Description: ', GOOGLE_DESC,\n'Respond only with a JSON object in the following format: {\n  \"Match\": 1,\n  \"Reasoning\": \"Concise explanation here\"\n}')\n) as match from google_amazon_matches\nwhere score < 0.8\nlimit 100;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a6aa7e32-b993-49ce-b564-d42a53c4b6cd",
   "metadata": {
    "language": "sql",
    "name": "cell17"
   },
   "outputs": [],
   "source": "select * from matches_w_claude LIMIT 10;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d4b23d4c-63d8-4ae3-97b5-bf4c4f5d02ad",
   "metadata": {
    "language": "sql",
    "name": "cell15"
   },
   "outputs": [],
   "source": "create or replace table snowflake_matches_claude\nas\nselect\namazon_id, \ngoogle_id, \namazon_desc,\ngoogle_desc,\ntry_parse_json(match):Match::int as match,\ntry_parse_json(match):Reasoning::varchar as reasoning\nfrom matches_w_claude\nwhere try_parse_json(match):Match::int = 1;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3585c021-3cec-4f31-9329-15bfa5d5c708",
   "metadata": {
    "language": "sql",
    "name": "cell16"
   },
   "outputs": [],
   "source": "\nselect * from snowflake_matches_claude;",
   "execution_count": null
  }
 ]
}